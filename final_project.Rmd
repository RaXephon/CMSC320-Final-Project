---
name: "Shashwat Kapoor, Jin Ah Kang, Theresa Choi"
output: html_document
---
##Table of Contents
I. Introduction
II. Problem
III. Data
IV. Analysis
  i. Statistical
  ii. Visual
V. Conclusion


####I. Introduction

####II. Problem

As the name implies, natural disasters occur from events in nature and are beyond human control. While it is impossible for humans to directly prevent the course of Mother Nature, we can still analyze the patterns of natural events and their implications. 

Of these, earthquakes are some of the most diverse in their effects. From undetectable tectonic plate movements to disasters with body counts in the thousands, earthquakes leave equal amounts of material to study and motive to do so.

If the government knew that a particular area was prone to earthquakes, they could avoid putting a housing complex there, preventing future tragedies. If tourists knew seismic seasonal trends would spike in their destination, they might choose a different vacation spot. 

As the above examples illustrate, decisions may be on a national or personal level or anywhere in between. Both, however, were fueled by public research based on data analysis.

For our tutorial, we decided to use a dataset on earthquakes near Japan.

####III. Data

**Including Libraries**
```{r setup, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(tibble)
library(tidyverse)
library(askpass)
library(datasets)
library(leaflet)
library(KernSmooth)
library(sp)
library(dummies)
library(Hmisc)
```

**Data Scraping/Tidying**

First we want to gather the raw data from our dataset. In this case, we can simply read it from a csv datatype using the function `read_csv`. 
```{r read_data, warning=FALSE, message=FALSE}
dat <- read_csv("Japan_earthquakes.csv")
```

Next, we select the columns that we are interested in. For our purposes, we only need `time`, `latitude`, `longitude`, `depth`, `mag`, `magType`, and `place`.
```{r}
ext_dat <- dat %>%
  select("time", "latitude", "longitude", "depth", "mag", "magType", "place")
ext_dat
```

Notice that the `time` column has a large amount of information, but none of it is currently easily accessible. We can break down this compact form into more columns. First we will make a copy of the `time` column, so we can parse each into time and date separately. To do this, we separate the date and the time via the delimiter " ". We do the same for the time, separating out `year`, `month`, and `day`.
```{r}
options(dplyr.width = Inf)
ext_dat$copy <- ext_dat$time

ext_dat <- ext_dat %>%
  separate(copy, sep=" ", into = c("date", "time_in_sec")) %>%
  separate(date, sep="-", into = c("year", "month", "day")) 
ext_dat
```

We can now take the original time column and transform it into a column of the `date` type, allowing R to perform date-specific computations on it. (We will additionally rename the date column from `time` to `date` to prevent confusion.)
```{r}
ext_dat <- ext_dat %>%
  mutate(time=as.Date(time))

colnames(ext_dat)[colnames(ext_dat) == "time"] <- "date"

ext_dat
```


####IV-i. Analysis -- Statistical

####IV-ii. Analysis -- Visual



```{r create season}
#separate seasons according to conditions
ext_dat <- mutate(ext_dat, seasons = ifelse(month >= "03" & month <= "05", "spring",
                   ifelse(month >= "06" & month <= "08", "summer", 
                   ifelse(month >= "09" & month <= "11", "fall", "winter"))))
```

```{r cor btwn depth and each season}
corr_spring <- ext_dat %>%
  filter(seasons == "spring") %>% 
  mutate(spring_depth = depth, spring_mag = mag) %>%
  select(spring_depth, spring_mag)

corr_summer <- ext_dat %>%
  filter(seasons == "summer") %>% 
  mutate(summer_depth = depth, summer_mag = mag) %>%
  select(summer_depth, summer_mag)

corr_fall <- ext_dat %>%
  filter(seasons == "fall") %>% 
  mutate(fall_depth = depth, fall_mag = mag) %>% 
  select(fall_depth, fall_mag)

corr_winter <- ext_dat %>%
  filter(seasons == "winter") %>% 
  mutate(winter_depth = depth, winter_mag = mag)%>%
  select(winter_depth, winter_mag)

#all seasons' p-value < 0.5 and therefore, their some form of correlation exist
cor(corr_spring)
cor(corr_summer)
cor(corr_fall)
cor(corr_winter)
```

```{r plotting}
attach(corr_spring)
plot(spring_mag, spring_depth, main = "Correlation  Spring", pch = 20)

attach(corr_summer)
plot(summer_mag, summer_depth, main = "Correlation  summer", pch = 20)

attach(corr_fall)
plot(fall_mag, fall_depth, main = "Correlation  fall", pch = 20)

attach(corr_winter)
plot(winter_mag, winter_depth, main = "Correlation  winter", pch = 20)
```

```{r mark Japan for ref}
icons <- awesomeIcons(
  icon = 'fa-flag',
  library = 'fa'
)

#mark at tokyo
japan_map <- leaflet(ext_dat) %>%
  addTiles() %>%
  setView(lng = 139.80, lat = 35.68, zoom = 6) %>% #tokyo lat, lng
  addAwesomeMarkers(lng = 139.80, lat = 35.68, icon=icons)

japan_map
```

```{r}
winter <- ext_dat[ext_dat$month %in% c("01", "02", "12"), ]
spring <- ext_dat[ext_dat$month %in% c("03", "04", "05"), ]
summer <- ext_dat[ext_dat$month %in% c("06", "07", "08"), ]
autumn <- ext_dat[ext_dat$month %in% c("09", "10", "11"), ]

japan_map %>%
  addTiles() %>%
  setView(lng = 139.80, lat = 35.68, zoom = 4) %>%
  addCircleMarkers(data=winter, stroke = FALSE, radius = 3, color = "#0080FF", group = "winter") %>%
  addCircleMarkers(data=spring, stroke = FALSE, radius = 3, color = "#29AB87", group = "spring") %>%
  addCircleMarkers(data=summer, stroke = FALSE, radius = 3, color = "#999900", group = "summer") %>%
  addCircleMarkers(data=autumn, stroke = FALSE, radius = 3, color = "#EA3C53", group = "autumn") %>%
  addLayersControl(overlayGroups = c("winter", "spring", "summer", "autumn"),
                    options = layersControlOptions(collapsed = FALSE)) %>%
  hideGroup("spring") %>%
  hideGroup("summer") %>%
  hideGroup("autumn")
```

```{r}
X=cbind(ext_dat$longitude,ext_dat$latitude)
kde2d <- bkde2D(X, bandwidth=c(bw.ucv(X[,1]),bw.ucv(X[,2])))

x=kde2d$x1
y=kde2d$x2
z=kde2d$fhat
CL=contourLines(x , y , z)

quake_density <- japan_map %>%
  setView(lng = 139.80, lat = 35.68, zoom = 4)

for (x in seq(1, length(CL))) {
  quake_density <- quake_density %>%
  addPolylines(CL[[x]]$x, CL[[x]]$y, color = "#8B0000", weight = 2) %>%
  addPolygons(CL[[x]]$x, CL[[x]]$y, fillColor = "red", stroke = FALSE)
}

quake_density
```


####V. Conclusion


TODO: 
1. correlation btwn depth and mag
2. hypothesis (mag sec1 = sec2 = sec3 = sec4)
3. ANOVA test to see the means of 'mb' 'mww' 'mwr' of mag are different
4. conclude with words
5. map to show the visual result to support our test 


so far, we did correlation, r test. that shows there some correlation exist between depth and each season. we found all of seasons have some form of correlation with depth.

---skip for now---
(now, we see if there is a linear relation btwn them. (Im sure we will find it), so now we can conclude that there is a linear relation exist btwn two. so, we can conclude that as depth goes deeper, the magnitude gets higher. )

now, we want to see if each season has the same mean of magnitude. so we conduct ANOVA test to see it. (hypothesis: all means are the same).
then derive the conclusion according to the result. 
(if the null is rejected, then say there are no differences by season, 
 if not rejected, then we say there are some differences by season)

lastly, show the map of earthquake by seasons.
